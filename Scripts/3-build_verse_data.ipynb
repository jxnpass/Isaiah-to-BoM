{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import spacy\n",
    "import textdistance\n",
    "import re\n",
    "import math\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "full_cr = pd.read_csv('../DirtyData/full_cross_ref.csv')\n",
    "final_cr = full_cr.copy()\n",
    "full_cr.fillna('NA', inplace=True)\n",
    "\n",
    "bd = pd.read_csv('../CleanData/Bible_Dictionary.csv')\n",
    "\n",
    "stop_words = list(set(stopwords.words('english'))) # useless words, used in function later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Clean scripture verses (Pre-Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_verses(verse_column):\n",
    "    \n",
    "    new_column = []\n",
    "    \n",
    "    for verse in verse_column:\n",
    "        if verse != 'NA':\n",
    "            verse = verse.replace('-', ' ')\n",
    "            verse = re.sub(r'[^a-zA-Z0-9\\s]', '', verse)   \n",
    "            verse = verse.lower() \n",
    "            verse = ' '.join([word for word in verse.split() if word not in stop_words])\n",
    "            verse = re.sub(r'\\d', '', verse)\n",
    "            # Certain words are spelled differently between books, such as \"woe\" and \"wo\"\n",
    "            verse = re.sub(r'\\bwoe\\b', 'wo', verse)\n",
    "            verse = re.sub(r'\\bshew\\b', 'show', verse)\n",
    "            verse = re.sub(r'\\bvail\\b', 'veil', verse)\n",
    "            verse = re.sub(r'\\bvails\\b', 'veils', verse)\n",
    "            # Append new verse\n",
    "            new_column.append(verse)\n",
    "\n",
    "        else:\n",
    "            new_column.append('NA')\n",
    "\n",
    "    return new_column\n",
    "\n",
    "full_cr['scripture_text_ISH'] = process_verses(full_cr['scripture_text_ISH'])\n",
    "final_cr['scripture_cleaned_ISH'] = full_cr['scripture_text_ISH']\n",
    "full_cr['scripture_text_BOM'] = process_verses(full_cr['scripture_text_BOM'])\n",
    "final_cr['scripture_cleaned_BOM'] = full_cr['scripture_text_BOM']\n",
    "bd['term_simple']  = process_verses(bd['Term'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find Text Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sim = []\n",
    "\n",
    "for i in full_cr.index:\n",
    "    BOM_value = full_cr.loc[i, ['scripture_text_BOM']][0]\n",
    "    if 'NA' not in BOM_value:\n",
    "        ISH_verse = full_cr.loc[i, ['scripture_text_ISH']][0]\n",
    "        ISH_words = ISH_verse.split()\n",
    "        BOM_verse = full_cr.loc[i, ['scripture_text_BOM']][0]\n",
    "        BOM_words = BOM_verse.split()\n",
    "        cosine_sim_dist = textdistance.cosine(ISH_words, BOM_words)\n",
    "    else:\n",
    "        cosine_sim_dist = 0\n",
    "    text_sim.append(cosine_sim_dist)\n",
    "\n",
    "final_cr['similarity_score'] = pd.Series(text_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### categories for similarity_score\n",
    "\n",
    "def categorize_similarity(score):\n",
    "    if score >= .75:\n",
    "        return \"Direct Quote\"\n",
    "    elif .25 <= score < .75:\n",
    "        return \"Shared Language\"\n",
    "    else: \n",
    "        return \"Similar Theme\"\n",
    "    \n",
    "temp = pd.DataFrame(final_cr[final_cr['scripture_text_BOM'].notna() & final_cr['scripture_text_ISH'].notna()]['similarity_score'].apply(categorize_similarity))\n",
    "temp.rename(columns = {'similarity_score': 'similarity_category'}, inplace=True)\n",
    "final_cr = final_cr.join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Count Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cr['word_count_ISH'] = final_cr['scripture_text_ISH'].apply(lambda verse: len(str(verse).split()) if not pd.isna(verse) else 0)\n",
    "final_cr['word_count_BOM'] = final_cr['scripture_text_BOM'].apply(lambda verse: len(str(verse).split()) if not pd.isna(verse) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Logical Vector if Bible Dictionary Term is Found Within BoM Verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_found_ISH = []\n",
    "bd_found_BOM = []\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for ISH_verse in full_cr['scripture_text_ISH']:\n",
    "    verse_words = ISH_verse.split()\n",
    "    found_word = False\n",
    "\n",
    "    for word in verse_words:\n",
    "        lemma = lemmatizer.lemmatize(word, 'n')\n",
    "        \n",
    "        if lemma in bd['term_simple'].values:\n",
    "            found_word = True\n",
    "            break  \n",
    "\n",
    "    if found_word:\n",
    "        bd_found_ISH.append(True)\n",
    "\n",
    "    else:\n",
    "        bd_found_ISH.append(False)\n",
    "\n",
    "for BOM_verse in full_cr['scripture_text_BOM']:\n",
    "    verse_words = BOM_verse.split()\n",
    "    found_word = False\n",
    "\n",
    "    for word in verse_words:\n",
    "        lemma = lemmatizer.lemmatize(word, 'n')\n",
    "        \n",
    "        if lemma in bd['term_simple'].values:\n",
    "            found_word = True\n",
    "            break  \n",
    "\n",
    "    if found_word:\n",
    "        bd_found_BOM.append(True)\n",
    "\n",
    "    else:\n",
    "        bd_found_BOM.append(False)\n",
    "\n",
    "final_cr['bible_term_in_ISH'] = bd_found_ISH\n",
    "final_cr['bible_term_in_BOM'] = bd_found_BOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Classify Isaiah Chapters\n",
    "CH 1-39: First (Proto) Isaiah \n",
    "\n",
    "CH 40-55: Second (Deutero) Isaiah \n",
    "\n",
    "CH 56-66: Third (Trito) Isaiah "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Duhms_Classification(ch_num):\n",
    "    if math.isnan(ch_num):\n",
    "        return np.nan\n",
    "    else:    \n",
    "        if (ch_num >=1) & (ch_num <= 39):\n",
    "            return 'Proto'\n",
    "        elif (ch_num >= 40) & (ch_num <= 55):\n",
    "            return 'Deutero'\n",
    "        elif (ch_num >= 56) & (ch_num <= 66):\n",
    "            return 'Trito'\n",
    "    \n",
    "\n",
    "Duhms_division = []\n",
    "\n",
    "for ch_num in final_cr['chapter_number_ISH']:\n",
    "    Duhms_division.append(Duhms_Classification(ch_num))\n",
    "\n",
    "final_cr['Duhms_Class'] = Duhms_division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export to XLSX and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cr.to_csv('../CleanData/by_verse_cross_ref.csv')\n",
    "final_cr.to_excel('../CleanData/by_verse_cross_ref.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
